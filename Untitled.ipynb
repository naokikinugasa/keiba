{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kinugasa\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel_launcher.py:268: RuntimeWarning: invalid value encountered in true_divide\n",
      "c:\\users\\kinugasa\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel_launcher.py:286: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "c:\\users\\kinugasa\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel_launcher.py:287: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "c:\\users\\kinugasa\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel_launcher.py:288: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "c:\\users\\kinugasa\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel_launcher.py:289: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "c:\\users\\kinugasa\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel_launcher.py:292: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "c:\\users\\kinugasa\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel_launcher.py:293: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "c:\\users\\kinugasa\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel_launcher.py:294: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   horsename  0\n",
      "0       グラーネ  1\n",
      "1  ココナッツクッキー  0\n",
      "2    アポロゴールド  1\n",
      "3       ヴァルト  1\n",
      "4   アマトリチャーナ  0\n",
      "5  ヴァーミリアグラン  0\n",
      "6    ホッカイノソラ  0\n",
      "7   コウエイリョウマ  1\n",
      "8     アルアンデス  1\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import pprint\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# driver = webdriver.Chrome(\"/Users/kinugasa/chromedriver_win32/chromedriver.exe\")\n",
    "\n",
    "# driver.get(\"https://db.netkeiba.com/?pid=race_top\")\n",
    "\n",
    "# a = driver.find_element_by_class_name(\"field\")\n",
    "# a.send_keys(\"園田\")\n",
    "# driver.find_element_by_class_name(\"form_side_btn\").click()\n",
    "\n",
    "# soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "\n",
    "# tr_list = soup.find(\"tbody\").find_all(\"tr\")\n",
    "# for tr in tr_list:\n",
    "#     td = tr.find(\"td\", class_=\"txt_l\")\n",
    "#     if td != None:\n",
    "#         # print(td.find(\"a\").get(\"href\"))\n",
    "\n",
    "# driver.close()\n",
    "# TODO:レース数増やす\n",
    "\n",
    "# def get_horse_url(race_url):\n",
    "\n",
    "#     base_url = \"https://db.netkeiba.com\"\n",
    "\n",
    "#     req = requests.get(race_url)\n",
    "#     soup = BeautifulSoup(req.content, 'html.parser')\n",
    "#     table1 = soup.find('table', attrs={'class':'race_table_01 nk_tb_common'})\n",
    "#     table2 = soup.findAll('td', attrs={'class':'txt_l'})\n",
    "#     horse_url_list = []\n",
    "#     for a in table2:\n",
    "#         b=a.find('a')\n",
    "#         if b != None:\n",
    "#             c=b.get('href')\n",
    "#             if \"horse\" in c:\n",
    "#                 horse_url_list.append(base_url + c)\n",
    "#     return horse_url_list\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_race_url_list(start_url, end_url, to_csv, Is_predict):\n",
    "    base_url = \"http://www2.keiba.go.jp/KeibaWeb\"\n",
    "    race_list = []\n",
    "    number_list = []\n",
    "    result_list = []\n",
    "\n",
    "    next_url = end_url\n",
    "    while next_url != start_url:\n",
    "        driver = webdriver.Chrome(\"/Users/kinugasa/chromedriver_win32/chromedriver.exe\")\n",
    "        driver.get(next_url)\n",
    "        driver.find_element_by_class_name(\"yesterday\").click()\n",
    "\n",
    "        soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "\n",
    "        tr_list = soup.find(\"section\", class_=\"raceTable\").find(\"table\").find_all(\"tr\", class_ = \"data\")\n",
    "\n",
    "        for tr in tr_list:\n",
    "            td_list = tr.find_all(\"td\")\n",
    "            url = tr.find(\"a\")\n",
    "            if url != None:\n",
    "                url = url.get(\"href\")[2:]\n",
    "                race_list.append(base_url + url)\n",
    "            number_list.append(td_list[8].string)\n",
    "\n",
    "        for tr in tr_list:\n",
    "            if Is_predict == False:\n",
    "                url = tr.find(\"a\", string=\"成績\")\n",
    "                if url != None:\n",
    "                    url = url.get(\"href\")[2:]\n",
    "                    result_list.append(base_url + url)\n",
    "            else:\n",
    "                result_list.append(\"url\")\n",
    "        next_url = str(driver.current_url)\n",
    "        driver.quit()\n",
    "\n",
    "    r = [race_list, number_list, result_list]\n",
    "    l = [list(x) for x in zip(*r)]\n",
    "    with open(to_csv, 'w') as f:\n",
    "        writer = csv.writer(f, lineterminator='\\n')\n",
    "        writer.writerows(l)\n",
    "\n",
    "    return l\n",
    "\n",
    "\n",
    "def get_result(race_url):\n",
    "    req = requests.get(race_url)\n",
    "    soup = BeautifulSoup(req.content, 'html.parser')\n",
    "    dbtbl = soup.find_all(\"td\", class_=\"dbtbl\")\n",
    "    horsecount = len(dbtbl[0].find_all(\"tr\")) - 2\n",
    "    data_list = [[0] * 3 for i in range(horsecount)]\n",
    "    for i in range(horsecount):\n",
    "        td_list = dbtbl[0].find_all(\"tr\")[2 + i].find_all(\"td\")\n",
    "        result = td_list[0].string\n",
    "        # TODO:数字以外除外しているが数字以外は0が入っている\n",
    "        if result.isdigit():\n",
    "            horsenum = td_list[2].string\n",
    "            time = td_list[11].string.strip()\n",
    "            data_list[i][0] = horsenum\n",
    "            data_list[i][1] = result\n",
    "            data_list[i][2] = time\n",
    "    df = pd.DataFrame(data_list, columns=[\"horsenum\", \"result\", \"time_result\"])\n",
    "    \n",
    "    # 払戻金\n",
    "    l = dbtbl[1].find(\"tr\", class_=\"dbdata\")\n",
    "    td_list = l.find_all(\"td\")\n",
    "    horsenum_r = [i.strip() for i in list(td_list[4].strings)]\n",
    "    multipul_wins = [int(i.strip().strip(\"円\").replace(\",\",\"\")) for i in list(td_list[5].strings)]\n",
    "    df2 = pd.DataFrame([horsenum_r, multipul_wins]).T\n",
    "    df2.columns = [\"horsenum\", \"multipul_wins\"]\n",
    "    df = pd.merge(df, df2, on=\"horsenum\", how=\"outer\")\n",
    "    df.fillna({\"multipul_wins\": 0}, inplace=True)\n",
    "    return df\n",
    "# print(get_result(\"http://www2.keiba.go.jp/KeibaWeb/TodayRaceInfo/RaceMarkTable?k_raceDate=2019%2f01%2f24&k_raceNo=11&k_babaCode=27\"))\n",
    "def get_horse_info(race_url, race_number):\n",
    "    req = requests.get(race_url)\n",
    "    soup = BeautifulSoup(req.content, 'html.parser')\n",
    "    tborder = soup.find(\"tr\", class_=\"tBorder\")\n",
    "    raceInfo = [[0] for i in range(race_number)]\n",
    "    # TODO:rangeを馬数で動的に\n",
    "    pastRace = [[0] for i in range(4)]\n",
    "    IsCancell_list = [False] * 4\n",
    "    \n",
    "    tr_list = soup.find(\"section\", class_=\"cardTable\").find_all(\"tr\")\n",
    "    # 23456\n",
    "    for h in range(race_number):\n",
    "        td_list_2 = tr_list[2 + 5*h].find_all(\"td\")\n",
    "        if td_list_2[1].get(\"class\") != None:\n",
    "            if td_list_2[1].get(\"class\")[0] == \"horseNum\":\n",
    "                plus_horsenum_index = 0\n",
    "        else:\n",
    "            plus_horsenum_index = -1\n",
    "        if td_list_2[2].find(\"a\").get(\"class\")[0] == \"horseName\":\n",
    "            plus_index = 0\n",
    "        else:\n",
    "            plus_index = -1\n",
    "        horsenum = td_list_2[1 + plus_horsenum_index].text\n",
    "        horsename = td_list_2[2 + plus_index].text\n",
    "        jockey = td_list_2[3 + plus_index].text.strip()\n",
    "        raceInfo[h].append(horsenum)\n",
    "        raceInfo[h].append(horsename)\n",
    "        raceInfo[h].append(jockey)\n",
    "        for i in range(0,4):\n",
    "            l = td_list_2[5 + plus_index + i].text.split()\n",
    "            # 過去走順位が取消かどうか\n",
    "            if l != []:\n",
    "                if l[0] == \"取消\":\n",
    "                    IsCancell_list[i] = True\n",
    "                else:\n",
    "                    IsCancell_list[i] = False\n",
    "            if IsCancell_list[i] == True or len(l) != 6:\n",
    "                l = []\n",
    "                for j in range(6):\n",
    "                    l.append(None)\n",
    "            pastRace[i].extend(l)\n",
    "            # pastRace[i].extend(td_list_2[5 + i].text.split())\n",
    "\n",
    "        td_list_3 = tr_list[3 + 5*h].find_all(\"td\")\n",
    "        trainer_weight = td_list_3[2].text\n",
    "        #TODO:前走のレースURL。リンクないものがあるので一時コメントアウト\n",
    "        # for i in range(0,4):\n",
    "        #     print(td_list_3[3 + i])\n",
    "        #     l = td_list_3[3 + i].find(\"a\").get(\"href\")\n",
    "        #     if l == []:\n",
    "        #         l.append(\"none\")\n",
    "        #     pastRace[i].append(l)\n",
    "            # pastRace[i].append(td_list_3[3 + i].find(\"a\").get(\"href\"))\n",
    "        \n",
    "        td_list_4 = tr_list[4 + 5*h].find_all(\"td\")\n",
    "        father = td_list_4[0].text\n",
    "        trainer = td_list_4[1].text\n",
    "        w = td_list_4[2].text\n",
    "        weight = w[:3]\n",
    "        if weight == \"－\" or weight == \"計不\":\n",
    "            weight = \"cancel\"\n",
    "        dhweight = w[4:len(w)-1]\n",
    "        if dhweight == \"\":\n",
    "            dhweight = 0\n",
    "        raceInfo[h].append(weight)\n",
    "        raceInfo[h].append(dhweight)\n",
    "        for i in range(0,4):\n",
    "            l = td_list_4[3 + i].text.split()\n",
    "            if l == [] or IsCancell_list[i] == True or len(l) != 4:\n",
    "                l = []\n",
    "                for j in range(4):\n",
    "                    l.append(None)\n",
    "            pastRace[i].extend(l)\n",
    "            # pastRace[i].extend(td_list_4[3 + i].text.split())\n",
    "        td_list_5 = tr_list[5 + 5*h].find_all(\"td\")\n",
    "        mother = td_list_5[0].text\n",
    "        for i in range(0,4):\n",
    "            l = td_list_5[2 + i].text.split()\n",
    "            if l == [] or IsCancell_list[i] == True or len(l) != 3:\n",
    "                # l = []がなかったら取れた分だけはlに入っているので、超えてしまう\n",
    "                l = []\n",
    "                for j in range(3):\n",
    "                    l.append(None)\n",
    "            pastRace[i].extend(l)\n",
    "\n",
    "            # pastRace[i].extend(td_list_5[2 + i].text.split())\n",
    "\n",
    "        td_list_6 = tr_list[6 + 5*h].find_all(\"td\")\n",
    "        grandfather = td_list_6[0].text\n",
    "        for i in range(0,4):\n",
    "            l = td_list_6[3 + i].text.split()\n",
    "            if l == [] or IsCancell_list[i] == True or len(l) != 2:\n",
    "                l = []\n",
    "                for j in range(2):\n",
    "                    l.append(None)\n",
    "            pastRace[i].extend(l)\n",
    "        \n",
    "        # [[],[]]→[]\n",
    "        x = []\n",
    "        for s in pastRace:\n",
    "            x.extend(s)\n",
    "        raceInfo[h].extend(x)\n",
    "        pastRace = [[0] for i in range(4)]\n",
    "        IsCancell_list = [False] * 4\n",
    "    \n",
    "    # pprint.pprint(raceInfo)\n",
    "    # f = open('some.csv', 'w')\n",
    "    # writer = csv.writer(f, lineterminator=\"\\n\")\n",
    "    # writer.writerows(raceInfo)\n",
    "    # f.close()\n",
    "    idx = pd.MultiIndex.from_arrays(\n",
    "        [['number','horsenum','horsename','jockey','weight','dhweight','past','past','past','past','past','past','past','past','past','past','past','past','past','past','past','past','past2','past2','past2','past2','past2','past2','past2','past2','past2','past2','past2','past2','past2','past2','past2','past2','past3','past3','past3','past3','past3','past3','past3','past3','past3','past3','past3','past3','past3','past3','past3','past3','past4','past4','past4','past4','past4','past4','past4','past4','past4','past4','past4','past4','past4','past4','past4','past4'],\n",
    "        ['number','horsenum','horsename','jockey','weight','dhweight','0','rank','date','race_weight','place','m','number','popularity','weight','jockey','jockey_weight','time','0-0-0-0','3f','difference','1st','0','rank','date','race_weight','place','m','number','popularity','weight','jockey','jockey_weight','time','0-0-0-0','3f','difference','1st','0','rank','date','race_weight','place','m','number','popularity','weight','jockey','jockey_weight','time','0-0-0-0','3f','difference','1st','0','rank','date','race_weight','place','m','number','popularity','weight','jockey','jockey_weight','time','0-0-0-0','3f','difference','1st']\n",
    "    ])\n",
    "    df = pd.DataFrame(raceInfo)\n",
    "    # if len(df.columns) > 70:\n",
    "    #     for i in range(len(df.columns) - 70):\n",
    "    #         df.drop([70 + i],axis=1, inplace=True)\n",
    "    df.columns = idx\n",
    "    # pd.set_option('display.max_columns', None)\n",
    "\n",
    "    return df\n",
    "    \n",
    "    \n",
    "def get_velocity(m, time):\n",
    "    time_sec_list = []\n",
    "    for t in list(time):\n",
    "        if t == None:\n",
    "            time_sec = 0\n",
    "        else:\n",
    "            base_time = pd.to_datetime('00:00.0', format='%M:%S.%f')\n",
    "            time = pd.to_datetime(t,errors='coerce', format='%M:%S.%f') - base_time\n",
    "            time_sec = time.total_seconds()\n",
    "        time_sec_list.append(time_sec)\n",
    "    # m = [float(mm[-4:]) if mm != None else 0 for mm in list(m)]\n",
    "    # リスト内包表記で書きたい\n",
    "    mmm = []\n",
    "    for mm in list(m):\n",
    "        if mm != None:\n",
    "            if len(mm) == 5:\n",
    "                mmm.append(float(mm[-4:]))\n",
    "            else:\n",
    "                mmm.append(float(mm[-3:]))\n",
    "        else:\n",
    "            mmm.append(0)\n",
    "    velocity = np.array(mmm)/np.array(time_sec_list)\n",
    "    return pd.Series(velocity)\n",
    "\n",
    "def data_processing(df):\n",
    "    # 出場取消馬の削除\n",
    "    df = df[df.weight.weight != \"cancel\"]\n",
    "    # TODO:データがないところを0で補完。タイムはその馬の平均値にしたい\n",
    "    # df.fillna(0,inplace=True)\n",
    "    \n",
    "    velocity1 = get_velocity(df[\"past\"][\"m\"], df[\"past\"][\"time\"])\n",
    "    velocity2 = get_velocity(df[\"past2\"][\"m\"], df[\"past2\"][\"time\"])\n",
    "    velocity3 = get_velocity(df[\"past3\"][\"m\"], df[\"past3\"][\"time\"])\n",
    "    velocity4 = get_velocity(df[\"past4\"][\"m\"], df[\"past4\"][\"time\"])\n",
    "    new_data = df[['horsenum','horsename','weight','dhweight']]\n",
    "    new_data.columns = ['horsenum', 'horsename','weight', 'dhweight']\n",
    "    \n",
    "    # new_data.dropna(subset=['weight'],inplace=True)\n",
    "    \n",
    "    new_data['velocity1'] = velocity1\n",
    "    new_data['velocity2'] = velocity2\n",
    "    new_data['velocity3'] = velocity3\n",
    "    new_data['velocity4'] = velocity4\n",
    "\n",
    "    mean = new_data[['velocity1','velocity2','velocity3','velocity4']].mean(axis=1)\n",
    "    new_data['avg_velocity'] = mean\n",
    "    new_data['weight'] = (new_data['weight'].astype(int) - new_data['weight'].astype(int).mean()) / new_data['weight'].astype(int).std()\n",
    "    new_data['dhweight'] = (new_data['dhweight'].astype(int) - new_data['dhweight'].astype(int).mean()) / new_data['dhweight'].astype(int).std()\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    n = new_data[['velocity1','velocity2','velocity3','velocity4','avg_velocity']]\n",
    "    l = (n.astype(float) - n.mean()) / n.std()\n",
    "    \n",
    "    l['weight'] = new_data[['weight']]\n",
    "    l['dhweight'] = new_data[['dhweight']]\n",
    "    l['horsename'] = new_data[['horsename']]\n",
    "    l['horsenum'] = new_data[['horsenum']]\n",
    "    # m = get_result(result_url)\n",
    "    # df = pd.merge(l, m, on=\"horsenum\", how=\"inner\")\n",
    "    # # TODO:上位３位を入れ替えではなく追加\n",
    "    # df.loc[df['result'].astype(int) <= 3, 'result'] = 1\n",
    "    # df.loc[df['result'].astype(int) > 3, 'result'] = 0\n",
    "    # df.fillna(df.median(),inplace=True)\n",
    "\n",
    "\n",
    "    return l\n",
    "\n",
    "def merge_info_and_result(info_df, result_url):\n",
    "    m = get_result(result_url)\n",
    "    df = pd.merge(info_df, m, on=\"horsenum\", how=\"inner\")\n",
    "    # TODO:上位３位を入れ替えではなく追加\n",
    "    df.loc[df['result'].astype(int) <= 3, 'result'] = 1\n",
    "    df.loc[df['result'].astype(int) > 3, 'result'] = 0\n",
    "    df.fillna(df.median(),inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def to_csv(url_list_csv, to_csv,Is_predict):\n",
    "    df = pd.read_csv(url_list_csv, names=('race_url','horse_num','result_url'))\n",
    "\n",
    "    # df2 = get_horse_info(\"http://www2.keiba.go.jp/KeibaWeb/TodayRaceInfo/DebaTable?k_raceDate=2019%2f01%2f18&k_raceNo=12&k_babaCode=27\",12)\n",
    "    # df3 = data_processing(df2, \"http://www2.keiba.go.jp/KeibaWeb/TodayRaceInfo/RaceMarkTable?k_raceDate=2019%2f01%2f18&k_raceNo=12&k_babaCode=27\")\n",
    "    for i in range(0,10):\n",
    "        # if i == 66 or i == 105 or i == 139 or i == 146 or i == 151 or i == 163 or i == 169 or i == 173:\n",
    "        #     continue\n",
    "        print(i)\n",
    "        df2 = get_horse_info(df.loc[i, 'race_url'],df.loc[i,'horse_num'])\n",
    "        # print(df2)\n",
    "        df3 = data_processing(df2)\n",
    "        if Is_predict == False:\n",
    "            df3 = merge_info_and_result(df3, df.loc[i,'result_url'])\n",
    "        # print(len(df3))\n",
    "        if i == 0:\n",
    "            df3.to_csv(to_csv)\n",
    "        else:\n",
    "            df3.to_csv(to_csv,mode=\"a\",header=False)\n",
    "# get_race_url_list(\"http://www2.keiba.go.jp/KeibaWeb/TodayRaceInfo/RaceList?k_raceDate=2019%2f02%2f07&k_babaCode=27\", \"http://www2.keiba.go.jp/KeibaWeb/TodayRaceInfo/RaceList?k_raceDate=2019%2f02%2f12&k_babaCode=27\", \"test.csv\", False)\n",
    "# to_csv('data_1_31.csv', '1_31.csv',True)\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "#TODO:引数をrace_urlだけにしたい\n",
    "def predict(race_url, horse_num):\n",
    "    race_df = get_horse_info(race_url,horse_num)\n",
    "    race_df = data_processing(race_df)\n",
    "\n",
    "    df = pd.read_csv(\"1_30.csv\")\n",
    "    df = df.dropna(how=\"any\")\n",
    "    train_X = df\n",
    "    train_y = df.result\n",
    "    race_df.dropna(how=\"any\", inplace=True)\n",
    "    test_X = race_df.reset_index(drop=True)\n",
    "    # test_y = test_X.result\n",
    "\n",
    "    sampler = RandomUnderSampler(ratio={0:train_X['result'].sum(), 1:train_X['result'].sum()}, random_state=42)\n",
    "    train_X, train_y = sampler.fit_resample(train_X, train_y)\n",
    "    train_X = pd.DataFrame(train_X)\n",
    "    Is_predict = True\n",
    "    train_X.columns = [\"num\",\"velocity1\",\"velocity2\",\"velocity3\",\"velocity4\",\"avg_velocity\",\"weight\",\"dhweight\",\"horsename\",\"horsenum\",\"result\",\"time_result\",\"multipul_wins\"]\n",
    "    knn = KNeighborsClassifier(n_neighbors=30) # インスタンス生成。\n",
    "    knn.fit(train_X.loc[:,'velocity1':'dhweight'], train_y)                 # モデル作成実行\n",
    "    # df3 = pd.read_csv(\"1_30.csv\")\n",
    "    # df3 = df3.dropna(how=\"any\")\n",
    "    pred_y = knn.predict(test_X.loc[:,'velocity1':'dhweight'])\n",
    "    # print(precision_recall_fscore_support(df3.result, pred_y))\n",
    "    df3 = pd.concat([test_X['horsename'],  pd.DataFrame(pred_y)], axis=1,)\n",
    "    pd.set_option('display.max_rows', None)\n",
    "    print(df3)\n",
    "\n",
    "def show_n_neighbors(data_csv):\n",
    "    df = pd.read_csv(data_csv)\n",
    "    df = df.dropna(how=\"any\")\n",
    "    train_X, test_X, train_y, test_y = train_test_split(\n",
    "        df.loc[:,'velocity1':'dhweight'], df.result, test_size=0.2)\n",
    "    accuracy = []\n",
    "    k_range = np.arange(1,100)\n",
    "    for k in k_range:\n",
    "        knn = KNeighborsClassifier(n_neighbors=k) # インスタンス生成。\n",
    "        knn.fit(train_X, train_y)                 # モデル作成実行\n",
    "        pred_y = knn.predict(test_X)              # 予測実行\n",
    "        accuracy.append(accuracy_score(test_y, pred_y)) # 精度格納\n",
    "    plt.plot(k_range, accuracy)\n",
    "    plt.show()\n",
    "predict(\"http://www2.keiba.go.jp/KeibaWeb/TodayRaceInfo/DebaTable?k_raceDate=2019%2f02%2f11&k_raceNo=1&k_babaCode=27\", 10)\n",
    "# print(precision_recall_fscore_support(test_y, pred_y))\n",
    "# sales  = (pred_y * test_X.multipul_wins).sum()\n",
    "# cost = pred_y.sum() * 100\n",
    "# profits = sales - cost\n",
    "# recovery_rate = sales/cost\n",
    "# print(sales)\n",
    "# print(cost)\n",
    "# print(profits)\n",
    "# print(recovery_rate)\n",
    "# TODO:前走空の場合それ以前のデータもとれていない\n",
    "#前走がどれくらい前か考慮していない\n",
    "#get_race_url_list()で全部読み込んだ後にcsv出力している。1行ごとに書き込みたい(止まった時のために)\n",
    "#出場取り消しの馬をmedianで埋めている。削除すべき。\n",
    "#過去走の行が個数個入っているか確認。３個が２個しかない等を全部noneにしている。使えるデータは使いたい。\n",
    "# 後ろから4個とっているため４桁mにしか対応できていない\n",
    "# get_race_url_list()のend_urlの1つ前までしかとれない仕様になっている"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
